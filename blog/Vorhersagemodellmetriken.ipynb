{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorhersagemodellmetriken für unausgeglichene Klassifizierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist sehr üblich, dass das Accuracy oft das erste Maß ist, das wir verwenden, wenn wir Modelle für unsere Klassifizierungsprobleme bewerten.\n",
    "\n",
    "In unserem Fall wird, aus den von uns verarbeiteten Modellen, das KNeighborsClassifier-Model mit dem besten Accuracy (accuracy_score: 89.09%) ausgewählt.\n",
    "In der Realität ist das Accuracy jedoch nicht als Kriterium für die Auswahl eines guten Vorhersagemodells für unseren Datenset geeignet, weil die Classification sehr unausgewogen ist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bibtex"
    }
   },
   "outputs": [],
   "source": [
    "# Untersuchung für target column 'IsBadBuy'\n",
    "print(pd.crosstab(target_test, columns = 'count' ))    # normalize = True\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bibtex"
    }
   },
   "outputs": [],
   "source": [
    "                                                                                # normalize = True\n",
    "                                                                                \n",
    "col_0     count                                                                 col_0        count\n",
    "IsBadBuy                                                                        IsBadBuy\n",
    "0          5716                                                                 0         0.871076\n",
    "1           846                                                                 1         0.128924\n",
    "(6562,)                                                                         (6562,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class 0 : class 1 = 87 % : 13 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Accuracy Paradox ist die genaue Benennung der Situation unserer Classification.\n",
    "Es ist der Fall, wo wir das ausgezeichnete Accuracy haben (z. B. 89 %), aber es spiegelt meistens nur die majority class(class 0) wider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In diesem Zusammenhang ist der f1-Score mehr für ein unausgeglichenes Klassifizierungsproblem geeignet als für das Accuracy.   Wir konzentrieren uns auf die f1-score und ich werde versuchen, mehr über den f-Beta-Score herauszufinden und auch den ROC_AOC Score damit zu vergleichen. Dies wird uns helfen, unsere Klassifizierung genauer zu analysieren und zu verstehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Wenn wir das Szenario betrachten, können wir sehen, welche Werte wichtiger und welche weniger wichtig sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Szenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bibtex"
    }
   },
   "outputs": [],
   "source": [
    "Ein Fehlkauf führt neben den Anschaffungskosten zu weiteren Kosten, wie der Einlagerung und Reparatur des Wagens. \n",
    "Deshalb ist es deiner Chefin wichtig, möglichst viele Fehlkäufe auszuschließen. Das darf allerdings nicht dazu führen, dass zu viele gute Käufe ausgeschlossen werden. \n",
    "Genauere Angaben zu den Kosten und Gewinnen der jeweiligen Käufe erhältst du für die Entwicklung des Prototyps noch nicht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das ‘**möglichst viele Fehlkäufe auszuschließen’** bedeutet, dass TP so groß wie möglich ist (oder FN so klein wie möglich ist).\n",
    "Das ‘**nicht zu viele gute Käufe ausgeschlossen werden’**   bedeutet, dass FP so klein wie möglich ist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comfusion Matrix \n",
    "\n",
    "    TP : True Positive vom Confusion Matrix\n",
    "\n",
    "    FP : False Positive vom Confusion Matrix\n",
    "You can do it inline like this\n",
    "\n",
    "<img style=\"margin:0px auto\" width =\"400\" src=\"confusionmatrix01.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben RandomForestClassifier, KNeighborsClassifier und LogisticRegression als Vorhersagemodelle verwendet, und die Bewertung wurde sowohl von f1 als auch von roc_aoc durchgeführt.\n",
    "\n",
    "Daraus lässt sich schließen, dass insgesamt sechs Modelle verglichen und analysiert worden sind.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Code  : Modelle erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bibtex"
    }
   },
   "outputs": [],
   "source": [
    "# RandomForestClassifier\n",
    "search_space_rf= {'max_depth': np.geomspace(start=1, stop=50, num=10, dtype='int'),\n",
    "                  'min_samples_leaf': np.geomspace(start=1, stop=500, num=10, dtype='int')}\n",
    "\n",
    "model_rf = GridSearchCV(estimator=RandomForestClassifier(n_estimators=10, class_weight= 'balanced',random_state=42, n_jobs=-1 ),   \n",
    "                            param_grid=search_space_rf ,               \n",
    "                            scoring='f1',                   # scoring='roc_auc'  \n",
    "                            cv=5,                       \n",
    "                            n_jobs=-1)                    \n",
    "model_rf.fit(features_train_selected, final_target_train)\n",
    "\n",
    "\n",
    "\n",
    "##  LogisticRegression\n",
    "pipeline_log  = Pipeline([('scaler', StandardScaler()), \n",
    "                          ('log', LogisticRegression(solver='lbfgs', max_iter=1e4, class_weight= 'balanced', n_jobs=-1))])\n",
    "C_values = np.geomspace(0.001, 1000, 14)\n",
    "\n",
    "search_space_log = [{'log__penalty' : ['l1', 'l2'], 'log__C':C_values }]\n",
    "model_log = GridSearchCV(estimator=pipeline_log,   \n",
    "                            param_grid=search_space_log ,               \n",
    "                            scoring='f1',                  # scoring='roc_auc'  \n",
    "                            cv=5,                        \n",
    "                            n_jobs=-1)                    \n",
    "model_log.fit(features_train_selected, final_target_train)\n",
    "\n",
    "\n",
    "\n",
    "# KNeighborsClassifier \n",
    "pipeline_std_knn = Pipeline([('std', StandardScaler()), \n",
    "                             ('knn', KNeighborsClassifier(n_jobs=-1))])\n",
    "\n",
    "k = np.geomspace(1, 200, 5, dtype='int')\n",
    "k = np.unique(k)\n",
    "search_space = {'knn__n_neighbors': k, 'knn__weights': ['uniform']}\n",
    "\n",
    "model_grid_knn = GridSearchCV(estimator=pipeline_std_knn,  \n",
    "                                 param_grid=search_space ,              \n",
    "                                 scoring='f1',                  # scoring='roc_auc'  \n",
    "                                 cv=5,                   \n",
    "                                 n_jobs=-1)                    \n",
    "model_grid_knn.fit(features_train_selected,final_target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ergebnis :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bibtex"
    }
   },
   "outputs": [],
   "source": [
    "model_rf                                                 model_grid_knn                                           model_log\n",
    "**************************************                   **************************************                   **************************************\n",
    "accuracy_score: 84.09%                                   accuracy_score: 89.09%                                   accuracy_score: 75.54%\n",
    "f05_score: 38.34%                                        f05_score: 50.80%                                        f05_score: 32.21%\n",
    "f1_score: 38.37%                                         f1_score: 33.08%                                         f1_score: 39.14%\n",
    "f2_score: 38.40%                                         f2_score: 24.53%                                         f2_score: 49.86%\n",
    "recall_score: 38.42%                                     recall_score: 20.92%                                     recall_score: 60.99%\n",
    "precision_score: 38.33%                                  precision_score: 79.02%                                  precision_score: 28.81%\n",
    "roc_auc_score: 64.63%                                    roc_auc_score: 60.05%                                    roc_auc_score: 69.34%\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "              precision  recall  f1-score  support                  precision  recall  f1-score  support                  precision  recall  f1-score  support\n",
    "\n",
    "           0       0.91    0.91      0.91     5714               0       0.99    0.89      0.94     6338               0       0.78    0.93      0.85     4771\n",
    "           1       0.38    0.38      0.38      848               1       0.21    0.79      0.33      224               1       0.61    0.29      0.39     1791\n",
    "\n",
    "    accuracy                         0.84     6562        accuracy                         0.89     6562        accuracy                         0.76     6562\n",
    "   macro avg       0.65    0.65      0.65     6562       macro avg       0.60    0.84      0.64     6562       macro avg       0.69    0.61      0.62     6562\n",
    "weighted avg       0.84    0.84      0.84     6562    weighted avg       0.97    0.89      0.92     6562    weighted avg       0.73    0.76      0.72     6562"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"margin:0px auto\" src=\"confusionmatrix02.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anwendungsvorschlag für F Beta Measure und Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Sind Sie Klassenlabels vorhergesagt?**\n",
    "    - **Ist die positive Klasse(1) wichtiger?**\n",
    "        - **Sind falsch negative und falsch positive Ergebnisse gleich wichtig?**\n",
    "            - F1-Mesaure verwenden\n",
    "        - **Sind falsch negative Ergebnisse wichtiger?**\n",
    "            - Verwenden Sie F2-Measure\n",
    "        - **Sind falsch positive Ergebnisse wichtiger?**\n",
    "            - F0.5-Mesaure verwenden\n",
    "            \n",
    "    - **Sind beide Klassen wichtig?**\n",
    "        - **Haben Sie weniger als 80% Beispiele für die Mehrheitsklasse?**\n",
    "            - Accuracy verwenden\n",
    "        - **Haben Sie mehr 80% Beispiele für die Mehrheitsklasse?**\n",
    "            - G-Mean verwenden\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Metrics Vergleichen und  das best geeignetste Modell auswählen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Metrics Vergleichen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauere Angaben zu den Kosten und Gewinnen der jeweiligen Käufe erhalten wir nicht.\n",
    "\n",
    "Wir könnten zunächst  annehmen, dass die positive Klasse(1) wichtiger  als die 0 Klasse ist.\n",
    "und nehmen wir an, die falsch negativen und falsch positiven Ergebnisse sind gleich wichtig.   \n",
    "    -  der durchschnittliche Verlust durch einen falschen Kauf und der durchschnittliche Gewinn durch einen guten Kauf sind gleich\n",
    "\n",
    "    d.H. wir vergleichen die F1 Score  und überprüfen welches Model die höchste Bewertung hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bibtex"
    }
   },
   "outputs": [],
   "source": [
    "1. **F1 Score**  \n",
    "    \n",
    "    model_log und model_log_roc haben beide den höchsten f1-Wert **39.14 %**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wieder aus unserem Szenario\n",
    "\n",
    "Das ‘**möglichst viele Fehlkäufe auszuschließen’** bedeutet, dass TP so groß wie möglich ist (oder FN so klein wie möglich ist)\n",
    "das ‘**nicht zu viele gute Käufe ausgeschlossen werden’**   bedeutet, dass FP so klein wie möglich ist\n",
    "\n",
    "TP : True Positive vom Confusion Matrix  \n",
    "FP : False Positive vom Confusion Matrix\n",
    "\n",
    "daher nehmen wir jetzt an, dass die positive Klasse wichtiger und gleichzeitig die FN wichtiger als FP ist. \n",
    "\n",
    "    d.H. wir vergleichen die F2 Score  und überprüfen welches Model die höchste Bewertung hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bibtex"
    }
   },
   "outputs": [],
   "source": [
    "2. **F2 Score**  \n",
    "    \n",
    "    model_log und model_log_roc haben beide den höchsten f2-Wert **49.86 %**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bibtex"
    }
   },
   "outputs": [],
   "source": [
    "3. **ROC_AOC** \n",
    "    \n",
    "    model_log und model_log_roc hat  den höchsten ROC_AOC-Wert **69.34 %**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Modellauswahl\n",
    "\n",
    "    Die LogisticRegression  wird gemäß den drei oben berechneten Metrikwerten als das beste Modell ausgewählt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Überlegung \n",
    "- Wenn der durchschnittliche Gewinn durch einen guten Kauf viel größer als  der Verlust von einem falschen Kauf ist,  werden wir den F0.5 Score bevorzugen.\n",
    "- in dem Fall model_grid_knn hat den höchsten F0.5-Wert **50.80%**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
